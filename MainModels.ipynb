{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPusOHADGGf5qI0iQLaxN3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tahm24/ModelB/blob/main/MainModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spacy Model Creation - Key word extractor (Custom Dataset)**"
      ],
      "metadata": {
        "id": "aHbsBE9jpeYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "!pip install -q spacy==3.8.5\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Imports\n",
        "import spacy\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from spacy.tokens import DocBin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "\n",
        "# Uploaded .jsonl file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Uploaded filename manually\n",
        "jsonl_file = list(uploaded.keys())[0]\n",
        "\n",
        "# Load custom NER data\n",
        "examples = []\n",
        "with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        text = data['text']\n",
        "        entities = data['entities']\n",
        "        examples.append((text, {\"entities\": [(start, end, label) for start, end, label in entities]}))\n",
        "\n",
        "print(f\" Loaded {len(examples)} training examples.\")\n",
        "\n",
        "# Split into train/dev\n",
        "train_data, dev_data = train_test_split(examples, test_size=0.1, random_state=42)\n",
        "\n",
        "# Helper to convert into spaCy format\n",
        "def create_docbin(data, nlp):\n",
        "    db = DocBin()\n",
        "    for text, annot in data:\n",
        "        doc = nlp.make_doc(text)\n",
        "        ents = []\n",
        "        for start, end, label in annot['entities']:\n",
        "            span = doc.char_span(start, end, label=label)\n",
        "            if span:\n",
        "                ents.append(span)\n",
        "        doc.ents = ents\n",
        "        db.add(doc)\n",
        "    return db\n",
        "\n",
        "# Create output folders\n",
        "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
        "nlp_blank = spacy.blank(\"en\")  # Blank English model\n",
        "\n",
        "create_docbin(train_data, nlp_blank).to_disk(\"data/train.spacy\")\n",
        "create_docbin(dev_data, nlp_blank).to_disk(\"data/dev.spacy\")\n",
        "\n",
        "# config file optimised for CPU\n",
        "!python -m spacy init config data/config.cfg --lang en --pipeline ner --optimize efficiency --force\n",
        "\n",
        "# Train model\n",
        "!python -m spacy train data/config.cfg --output model --paths.train data/train.spacy --paths.dev data/dev.spacy --gpu-id -1\n",
        "\n",
        "print(\"\\n Model Training Complete!\")\n",
        "\n",
        "# Load and test trained model via data outside training / testval\n",
        "import spacy\n",
        "\n",
        "nlp_trained = spacy.load(\"model/model-best\")\n",
        "\n",
        "# Test text\n",
        "test_text = \"\"\"\n",
        "John Doe — Backend Developer skilled in Python, Flask, and PostgreSQL.\n",
        "Worked at DevSolutions Ltd from 2020-2024. MSc Computer Science, University of Manchester.\n",
        "\"\"\"\n",
        "\n",
        "doc = nlp_trained(test_text)\n",
        "\n",
        "print(\"\\nEntities Found:\\n\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} ({ent.label_})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ltdV9qXa9PeS",
        "outputId": "3d8df22b-b8bd-4b71-9836-b78b74667b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e8ee3eaa-089e-4aa8-a7c7-8b4baced9f54\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e8ee3eaa-089e-4aa8-a7c7-8b4baced9f54\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving software_cv_ner2.json to software_cv_ner2 (1).json\n",
            "✅ Loaded 17 training examples.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "data/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory: model\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     35.83    0.00    0.00    0.00    0.00\n",
            " 37     200        190.25   1447.47    0.00    0.00    0.00    0.00\n",
            " 81     400          0.02      0.03    0.00    0.00    0.00    0.00\n",
            "134     600          0.07      0.08    0.00    0.00    0.00    0.00\n",
            "201     800          0.00      0.00    0.00    0.00    0.00    0.00\n",
            "284    1000          0.00      0.00    0.00    0.00    0.00    0.00\n",
            "384    1200          0.67      0.58    0.00    0.00    0.00    0.00\n",
            "484    1400          0.00      0.00    0.00    0.00    0.00    0.00\n",
            "652    1600          0.00      0.00    0.00    0.00    0.00    0.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model/model-last\n",
            "\n",
            "✅ Model Training Complete!\n",
            "\n",
            "Entities Found:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# CV text\n",
        "cv_text = \"\"\"\n",
        "James Carter\n",
        "Email: james.carter@example.com\n",
        "Phone: +44 1234 567890\n",
        "LinkedIn: linkedin.com/in/jamescarter\n",
        "GitHub: github.com/jcarter\n",
        "Location: London, UK\n",
        "\n",
        "Professional Summary\n",
        "Software Engineer with 4+ years of experience in designing, developing, and maintaining scalable software solutions. Adept in Java, Python, and JavaScript frameworks, with strong skills in Agile methodologies, teamwork, and problem-solving.\n",
        "\n",
        "Technical Skills\n",
        "Languages: Java, Python, JavaScript, C++\n",
        "Frameworks: React, Angular, Node.js, Django, Spring Boot\n",
        "Tools & Platforms: Git, Docker, Kubernetes, AWS, Azure, Jenkins\n",
        "Databases: MySQL, PostgreSQL, MongoDB\n",
        "\n",
        "Professional Experience\n",
        "Software Engineer | TechSolutions Ltd., London, UK\n",
        "March 2021 – Present\n",
        "Responsibilities:\n",
        "- Developed and maintained web applications using React, Node.js, and MongoDB.\n",
        "- Improved application performance by 25% through code optimisation and refactoring.\n",
        "- Led integration of RESTful APIs, enhancing application scalability.\n",
        "- Collaborated with cross-functional teams using Agile methodologies.\n",
        "\n",
        "Junior Software Developer | Innovatech Inc., London, UK\n",
        "January 2019 – February 2021\n",
        "Responsibilities:\n",
        "- Assisted in developing backend systems with Java (Spring Boot) and Python (Django).\n",
        "- Contributed to database design and management, optimising query performance by 15%.\n",
        "- Participated in code reviews, debugging sessions, and maintained coding standards.\n",
        "\n",
        "Education\n",
        "BSc Computer Science | University College London, UK | Graduated: 2018\n",
        "\n",
        "Certifications\n",
        "- AWS Certified Solutions Architect – Associate (2022)\n",
        "- Oracle Certified Java Programmer (2021)\n",
        "\n",
        "Projects\n",
        "Inventory Management System (React, Node.js, MongoDB) – Developed a full-stack web application to manage warehouse inventory.\n",
        "Chat Application (Java, Spring Boot, WebSocket) – Created a real-time chat application with secure authentication.\n",
        "\n",
        "Languages\n",
        "- English (Native)\n",
        "- French (Intermediate)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the extracted fields\n",
        "extracted_info = {}\n",
        "\n",
        "# Extract name (first non-empty line)\n",
        "lines = [line.strip() for line in cv_text.strip().split('\\n') if line.strip()]\n",
        "extracted_info['Name'] = lines[0]\n",
        "\n",
        "# Extract email\n",
        "email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', cv_text)\n",
        "extracted_info['Email'] = email_match.group(0) if email_match else None\n",
        "\n",
        "# Extract phone number\n",
        "phone_match = re.search(r'\\+?\\d[\\d\\s\\-]{7,}\\d', cv_text)\n",
        "extracted_info['Phone'] = phone_match.group(0) if phone_match else None\n",
        "\n",
        "# Extract LinkedIn URL\n",
        "linkedin_match = re.search(r'linkedin\\.com\\/[^\\s]+', cv_text)\n",
        "extracted_info['LinkedIn'] = linkedin_match.group(0) if linkedin_match else None\n",
        "\n",
        "# Extract Professional Title (first line under \"Professional Summary\")\n",
        "prof_summary_match = re.search(r'Professional Summary\\n([^\\n]+)', cv_text)\n",
        "if prof_summary_match:\n",
        "    first_line_summary = prof_summary_match.group(1)\n",
        "    # Assume the profession is the first few words before \"with\" or comma\n",
        "    profession_match = re.match(r'(.+?)(?: with|,)', first_line_summary)\n",
        "    extracted_info['Profession Title'] = profession_match.group(1) if profession_match else first_line_summary\n",
        "\n",
        "# Extract Years of Experience\n",
        "years_match = re.search(r'(\\d+)\\+?\\s*years? of experience', cv_text, re.IGNORECASE)\n",
        "extracted_info['Years of Experience'] = years_match.group(1) if years_match else None\n",
        "\n",
        "# Print all extracted fields\n",
        "for field, value in extracted_info.items():\n",
        "    print(f\"{field}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_V7dCvM-tKx",
        "outputId": "2f227aeb-173f-41f7-a950-e7d4929ea170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: James Carter\n",
            "Email: james.carter@example.com\n",
            "Phone: +44 1234 567890\n",
            "LinkedIn: linkedin.com/in/jamescarter\n",
            "Profession Title: Software Engineer\n",
            "Years of Experience: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Trained Model using all-mpnet-V2**"
      ],
      "metadata": {
        "id": "BVJOzGNhB5mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers python-docx\n",
        "\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import logging\n",
        "from transformers.utils import logging as hf_logging\n",
        "import numpy as np\n",
        "\n",
        "# Logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "hf_logging.set_verbosity_info()\n",
        "\n",
        "class CVMatcher:\n",
        "    def __init__(self, model_name='all-mpnet-base-v2', device=None):\n",
        "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        logging.info(f\"Loading model: {model_name} on {self.device}\")\n",
        "        self.model = SentenceTransformer(model_name, device=self.device)\n",
        "        logging.info(\"Model loaded successfully.\")\n",
        "\n",
        "    def segment_text(self, text, max_length=256):\n",
        "        segments = []\n",
        "        current = []\n",
        "        count = 0\n",
        "        for line in text.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            current.append(line)\n",
        "            count += len(line.split())\n",
        "            if count >= max_length:\n",
        "                segments.append(' '.join(current))\n",
        "                current = []\n",
        "                count = 0\n",
        "        if current:\n",
        "            segments.append(' '.join(current))\n",
        "        return segments\n",
        "\n",
        "    def compute_similarity(self, cv_text, job_text) -> float:\n",
        "        cv_chunks = self.segment_text(cv_text)\n",
        "        job_chunks = self.segment_text(job_text)\n",
        "\n",
        "        print(f\"Comparing {len(cv_chunks)} CV segments to {len(job_chunks)} job segments...\")\n",
        "\n",
        "        cv_embeddings = self.model.encode(cv_chunks, convert_to_tensor=True)\n",
        "        job_embeddings = self.model.encode(job_chunks, convert_to_tensor=True)\n",
        "\n",
        "        sim_matrix = util.cos_sim(cv_embeddings, job_embeddings).cpu().numpy()\n",
        "        max_sim = np.max(sim_matrix)\n",
        "\n",
        "        print(f\"Max segment similarity: {max_sim * 100:.2f}%\")\n",
        "        return max_sim * 100\n",
        "\n",
        "    def rank_jobs(self, cv: str, jobs: dict, top_k: int = None, verbose=True):\n",
        "        print(\"Ranking jobs based on similarity to the CV\\n\")\n",
        "        results = []\n",
        "        for title, desc in jobs.items():\n",
        "            print(f\"Evaluating job: {title}\")\n",
        "            score = self.compute_similarity(cv, desc)\n",
        "            results.append((title, score))\n",
        "        ranked = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "        if verbose:\n",
        "            print(\"\\nFinal Job Matching Results:\")\n",
        "            for title, score in ranked[:top_k or len(ranked)]:\n",
        "                print(f\" - {title:40s}: {score:.2f}%\")\n",
        "        return ranked\n"
      ],
      "metadata": {
        "id": "Wm2I7GwCEgMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import docx\n",
        "import os\n",
        "\n",
        "# Upload CV\n",
        "uploaded = files.upload()\n",
        "docx_filename = next(iter(uploaded))\n",
        "\n",
        "# Read CV text\n",
        "def read_docx_text(path):\n",
        "    doc = docx.Document(path)\n",
        "    return \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
        "\n",
        "cv_text = read_docx_text(docx_filename)\n",
        "\n",
        "# jobs test\n",
        "jobs = {\n",
        "    \"Software Engineer (React/AWS)\": \"\"\"\n",
        "        We are seeking a full-stack software engineer to develop cloud-native applications using React, Node.js,\n",
        "        and AWS. Experience with containerisation tools like Docker and CI/CD pipelines using Jenkins is required.\n",
        "        Must be a strong team player and comfortable working in Agile environments.\n",
        "    \"\"\",\n",
        "    \"Data Scientist\": \"\"\"\n",
        "        We are looking for a Data Scientist with solid experience in Python, deep learning, and ML frameworks like\n",
        "        PyTorch and TensorFlow. Knowledge in NLP, pandas, scikit-learn, and AWS is highly desirable. Candidates\n",
        "        should be able to build models, run experiments, and deliver production-grade systems.\n",
        "    \"\"\",\n",
        "    \"Random Text\": \"I have quick react speed on cars\"\n",
        "}\n",
        "\n",
        "# Run matcher\n",
        "matcher = CVMatcher()\n",
        "matcher.rank_jobs(cv=cv_text, jobs=jobs)\n",
        "\n",
        "# Cleanup uploaded file\n",
        "os.remove(docx_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "63GlX4LDNs1l",
        "outputId": "d47a61de-237f-496c-ff8b-ae75d018bc08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6cd147b5-f526-4352-86e7-33da4337a986\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6cd147b5-f526-4352-86e7-33da4337a986\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Machine_Learning_CV.docx to Machine_Learning_CV.docx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-mpnet-base-v2/snapshots/12e86a3c702fc3c50205a8db88f0ec7c0b6b94a0/config.json\n",
            "Model config MPNetConfig {\n",
            "  \"architectures\": [\n",
            "    \"MPNetForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"mpnet\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"vocab_size\": 30527\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-mpnet-base-v2/snapshots/12e86a3c702fc3c50205a8db88f0ec7c0b6b94a0/model.safetensors\n",
            "All model checkpoint weights were used when initializing MPNetModel.\n",
            "\n",
            "All the weights of MPNetModel were initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MPNetModel for predictions without further training.\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-mpnet-base-v2/snapshots/12e86a3c702fc3c50205a8db88f0ec7c0b6b94a0/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-mpnet-base-v2/snapshots/12e86a3c702fc3c50205a8db88f0ec7c0b6b94a0/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-mpnet-base-v2/snapshots/12e86a3c702fc3c50205a8db88f0ec7c0b6b94a0/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-mpnet-base-v2/snapshots/12e86a3c702fc3c50205a8db88f0ec7c0b6b94a0/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking jobs based on similarity to the CV\n",
            "\n",
            "Evaluating job: Software Engineer (React/AWS)\n",
            "Comparing 2 CV segments to 1 job segments...\n",
            "Max segment similarity: 48.83%\n",
            "Evaluating job: Data Scientist\n",
            "Comparing 2 CV segments to 1 job segments...\n",
            "Max segment similarity: 70.55%\n",
            "Evaluating job: Random Text\n",
            "Comparing 2 CV segments to 1 job segments...\n",
            "Max segment similarity: 18.17%\n",
            "\n",
            "Final Job Matching Results:\n",
            " - Data Scientist                          : 70.55%\n",
            " - Software Engineer (React/AWS)           : 48.83%\n",
            " - Random Text                             : 18.17%\n"
          ]
        }
      ]
    }
  ]
}